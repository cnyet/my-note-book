#!/usr/bin/env python3
"""
Life Secretary Agent - v2.0
Responsible for lifestyle management including diet, exercise, and health.
Refactored to inherit from BaseAgent with Memory and standardized lifecycle.
"""

import logging
from typing import Dict, Any, List, Optional
from datetime import datetime
from agents.base import BaseAgent

logger = logging.getLogger(__name__)

class LifeAgent(BaseAgent):
    """AI-powered lifestyle management agent."""

    def __init__(self, **kwargs):
        super().__init__(name="Life", **kwargs)

        # Standard user profile
        self.user_profile = {
            "name": "å¤§æ´ª",
            "age": 37,
            "occupation": "æŠ€æœ¯ä¸“å®¶",
            "location": "ä¸Šæµ·",
            "health_goals": {
                "weight": "maintain",
                "target_exercise_per_week": 3,
                "sleep_target": 8,
                "water_target": 2000,
            }
        }

    def _collect_data(self, **kwargs) -> Dict[str, Any]:
        """Step 1: Gather raw life/health data."""
        logger.info("ðŸŒ± Collecting lifestyle data and health metrics...")
        
        # In v2.0, we collect:
        # 1. Current timestamp info
        # 2. Any visual data passed via kwargs (from API)
        # 3. Health metrics (placeholder for integration)
        
        data = {
            "date": datetime.now().strftime("%Y-%m-%d"),
            "day_of_week": datetime.now().strftime("%A"),
            "user_profile": self.user_profile,
            "vision_data": kwargs.get("vision_results", None),
            "health_metrics": self._get_placeholder_metrics()
        }
        
        return data

    def _process_with_llm(self, raw_data: Any, historical_context: str = "", **kwargs) -> str:
        """Step 2: Transform life data into a personalized plan."""
        logger.info("ðŸ¤– Generating lifestyle plan using LLM...")
        
        prompt_content = self._prepare_prompt(raw_data, historical_context)
        
        messages = [
            {
                "role": "system",
                "content": """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç”Ÿæ´»ç®¡ç†é¡¾é—®ï¼Œä¸º37å²çš„æŠ€æœ¯ä¸“å®¶å¤§æ´ªæä¾›ä¸ªæ€§åŒ–çš„ç”Ÿæ´»æ–¹å¼å»ºè®®ã€‚
ä½ çš„èŒè´£ï¼š
1. æä¾›ç§‘å­¦çš„é¥®é£Ÿå»ºè®®
2. åˆ¶å®šåˆç†çš„è¿åŠ¨è®¡åˆ’
3. ä¼˜åŒ–ä½œæ¯æ—¶é—´å®‰æŽ’
4. ç»™å‡ºå¥åº·ç”Ÿæ´»å°è´´å£«

è¯·å§‹ç»ˆä»¥ä¸“ä¸šã€è´´å¿ƒã€åŠ¡å®žçš„æ–¹å¼æä¾›å»ºè®®ï¼Œå¹¶å……åˆ†åˆ©ç”¨æä¾›çš„åŽ†å²èƒŒæ™¯å’Œåå¥½ã€‚""",
            },
            {"role": "user", "content": prompt_content},
        ]

        response = self.llm.send_message(
            messages=messages, max_tokens=2000, temperature=0.7
        )

        if response and isinstance(response, str):
            return response
            
        return "âŒ æ— æ³•ç”Ÿæˆç”Ÿæ´»å»ºè®®ï¼Œè¯·æ£€æŸ¥ LLM é…ç½®ã€‚"

    def _prepare_prompt(self, data: Dict[str, Any], historical_context: str) -> str:
        """Prepare context for LLM."""
        profile = data["user_profile"]
        
        context_str = f"""è¯·ä¸ºä»Šæ—¥åˆ¶å®šç”Ÿæ´»ç®¡ç†è®¡åˆ’ã€‚

ã€ç”¨æˆ·ä¿¡æ¯ã€‘
- å§“åï¼š{profile['name']}ï¼Œ{profile['age']}å²ï¼Œ{profile['occupation']}
- åœ°ç‚¹ï¼š{profile['location']}
- ç›®æ ‡ï¼šç¡çœ {profile['health_goals']['sleep_target']}h, é¥®æ°´{profile['health_goals']['water_target']}ml

ã€å½“å‰çŠ¶æ€/æ•°æ®ã€‘
- æ—¥æœŸï¼š{data['date']} ({data['day_of_week']})
"""
        if data.get("vision_data"):
            context_str += f"- è§†è§‰è¯†åˆ«è¾“å…¥ï¼š{data['vision_data']}\n"
            
        if historical_context:
            context_str += f"\nã€åŽ†å²å¥åº·è®°å½•/åå¥½ã€‘\n{historical_context}\n"

        context_str += """
è¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼š
# ä»Šæ—¥ç”Ÿæ´»ç®¡ç† - [æ—¥æœŸ]

## ðŸ¥— é¥®é£Ÿè®¡åˆ’
- æ—©é¤ï¼š...
- åˆé¤ï¼š...
- æ™šé¤ï¼š...
- é¥®æ°´æé†’ï¼š...

## ðŸƒâ€â™‚ï¸ è¿åŠ¨å®‰æŽ’
...

## â° ä½œæ¯ä¸Žç²¾åŠ›å»ºè®®
...

## ðŸ’¡ å¥åº·å°è´´å£«
...
"""
        return context_str

    def _get_placeholder_metrics(self) -> Dict[str, Any]:
        """Placeholder for real health data integration."""
        return {
            "weight": 75,
            "steps_yesterday": 8500,
            "sleep_last_night": 7.5
        }

    def interactive_mode(self):
        """Standardized interactive mode for CLI usage."""
        print("\n" + "=" * 70)
        print("ðŸŒ± Life Agent - Interactive Mode")
        print("=" * 70)
        
        print("\nðŸ¤– Running agent pipeline...")
        result = self.execute()
        
        print("\n" + "=" * 70)
        print(result)
        print("=" * 70)
        
        return result

if __name__ == "__main__":
    agent = LifeAgent()
    agent.interactive_mode()
